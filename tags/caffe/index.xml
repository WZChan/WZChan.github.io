<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Caffe on WZChan&#39;s Blog</title>
    <link>https://wzchan.github.io/tags/caffe/</link>
    <description>Recent content in Caffe on WZChan&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© Copyright By WZChan.</copyright>
    <lastBuildDate>Mon, 18 Dec 2017 11:19:00 +0800</lastBuildDate>
    
	<atom:link href="https://wzchan.github.io/tags/caffe/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Windows Caffe计算图片均值</title>
      <link>https://wzchan.github.io/post/caffe/compute_image_mean/</link>
      <pubDate>Mon, 18 Dec 2017 11:19:00 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/compute_image_mean/</guid>
      <description>图片在减均值后，会提高训练与预测的精度和速度。
1、二进制格式的均值计算 ../caffe/build/tools/Release/compute_image_mean ../file_name_lmdb /../mean.binaryproto  具体命令如上。
2、Python格式的均值计算 需要用到Python接口或者进行特征可视化，需要Python格式的均值文件。 具体Python脚本如下：
import numpy as np import sys,caffe if len(sys.argv)!=3: print &amp;quot;Usage: python convert_mean.py mean.binaryproto mean.npy&amp;quot; sys.exit() blob = caffe.proto.caffe_pb2.BlobProto() bin_mean = open( sys.argv[1] , &#39;rb&#39; ).read() blob.ParseFromString(bin_mean) arr = np.array( caffe.io.blobproto_to_array(blob) ) npy_mean = arr[0] np.save( sys.argv[2] , npy_mean )  两个参数： 1、mean.binaryproto 二进制均值文件保存路径和文件名 2、mean.npy Python格式的均值文件保存路径和文件名</description>
    </item>
    
    <item>
      <title>Caffe模型日志级别设置(Python)</title>
      <link>https://wzchan.github.io/post/caffe/caffe%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB%E8%AE%BE%E7%BD%AEpython/</link>
      <pubDate>Fri, 15 Dec 2017 16:18:20 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/caffe%E6%A8%A1%E5%9E%8B%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB%E8%AE%BE%E7%BD%AEpython/</guid>
      <description>在训练Caffe模型的时候，可能会根据需要做一些对于Caffe加载模型时日志的显示，代码如下:
os.environ[&#39;GLOG_minloglevel&#39;] = &#39;2&#39; import caffe  具体的日志级别如下：
0 - debug 1 - info (still a LOT of outputs) 2 - warnings 3 - errors  </description>
    </item>
    
    <item>
      <title>Win10&#43;Anaconda2&#43;vs2015&#43;cuDnn&#43;CUDA8.0安装caffe时需要注意的问题</title>
      <link>https://wzchan.github.io/post/caffe/win10&#43;anconda2&#43;vs2015&#43;cudnn&#43;cuda8.0%E5%AE%89%E8%A3%85caffe%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 13 Dec 2017 12:27:46 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/win10&#43;anconda2&#43;vs2015&#43;cudnn&#43;cuda8.0%E5%AE%89%E8%A3%85caffe%E6%97%B6%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>总体的安装步骤按照官方文档或是windows10下用ninja编译配置caffe 在编译caffe实验环境的时候。应当对build_win.cmd中的内容进行相应的修改。
但是我在按照文章中进行编译时，会有一些错误，下面进行说明：
1、由于在官方知道说明文件中需要利用ninja来进行编译，目的是减少编译的时间，但是不知道我的电脑为什么，使用ninja编译的时候来时会报错： ninja: build stopped: subcommand failed.
2、同时在进行ninja指令单独执行的时候后，会出现错误： ninja: error: loading &#39;build.ninja&#39;: 系统找不到指定的文件。的错误。 但是按照我找到的一篇直接利用 Python+ git编译ninjawindows 安装ninja的文章编译后，生成的文件夹中使用ninja时不会报出该错误。 所以猜测，可能是ninja的用法有误。 解决方法： 在编译caffe的时候修改build_win.cmd文件中控制是否用ninja的参数，如下：
 :: Change to 1 to use Ninja generator (builds much faster) if NOT DEFINED WITH_NINJA set WITH_NINJA=0  将 = 号后原本为1 的内容改为 0，利用GCC去编译。 虽然时间会稍微久一点，但是不影响后续的使用。
除此之外，在进行build_win.cmd的时候，由于限于我国特殊国情，所以有些prebuild的组件下不下来，鉴于此我找到了github的一个链接，可以把它下下来放在相应的文件夹内，Caffe: Problem in downloading prebuilt dependenies #5679</description>
    </item>
    
    <item>
      <title>Caffe命令备忘</title>
      <link>https://wzchan.github.io/post/caffe/caffe%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98/</link>
      <pubDate>Wed, 06 Dec 2017 16:42:12 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/caffe%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98/</guid>
      <description>1. Train阶段 2. Test阶段 root_to_caffe/build/tools/caffe test
-model 指定模型描述文件文本
-weights 使用权重model
-gpu 选用gpu设备
-log_dir 保存log位置</description>
    </item>
    
    <item>
      <title>用draw_net.py绘制网络图时的小问题</title>
      <link>https://wzchan.github.io/post/caffe/%E7%94%A8draw_net.py%E7%BB%98%E5%88%B6%E7%BD%91%E7%BB%9C%E5%9B%BE%E6%97%B6%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98/</link>
      <pubDate>Wed, 06 Dec 2017 15:18:22 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/%E7%94%A8draw_net.py%E7%BB%98%E5%88%B6%E7%BD%91%E7%BB%9C%E5%9B%BE%E6%97%B6%E7%9A%84%E5%B0%8F%E9%97%AE%E9%A2%98/</guid>
      <description>在Windows10下利用Caffe的Python接口进行绘制神经网络模型图时，出现了如下问题：
1. 无法加载pydot
解决方法：
在安装了Anconda的前提下使用
conda install pydot
但是由于conda设置之类的事情说是没办法找到相应的channel和下载文件。Google了一下，发现需要提前安装一下graphviz，于是：
conda install graphviz
安装成功之后继续：
conda install pydot
发现还是出错了，头皮发麻，用了pip：
pip install pydot
终于提示安装成功。
至此解决了pydot和graphviz的问题。
2. 运行draw_net.py后有报错
pydot find_graphviz = pydot.graphviz.find_graphviz &#39;module&#39; object has no attribute &#39;graphviz&#39;  这个看了draw_net.py的源码，把文件中所有相应的pydot.graphviz改为pydot即可。
可能是由于pydot的版本不一样造成的结果。</description>
    </item>
    
    <item>
      <title>用Caffe Python实现一个两层神经网络</title>
      <link>https://wzchan.github.io/post/caffe/%E7%94%A8caffe-python%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%B8%A4%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 06 Dec 2017 15:17:28 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/%E7%94%A8caffe-python%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%B8%A4%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
      <description>1. 首先准备一下原始数据 # *-* coding: utf-8 *-* import pickle import numpy as np # 划分类别的边界 def cos_curve(x): return 0.25*np.sin(2*x*np.pi+0.5*np.pi) + 0.5 # samples保存二维点的坐标，labels标明类别 np.random.seed(123) samples = [] labels = [] # 单位空间内平均样本数为50 sample_density = 50 for i in range(sample_density): x1, x2 = np.random.random(2) # 计算当前x1对应的分类边界 bound = cos_curve(x1) # 为了方便可视化，舍弃太靠近边界的样本 if bound - 0.1 &amp;lt; x2 &amp;lt;= bound + 0.1: continue else: samples.append((x1, x2)) # 打标签，上半部分为1，下半部分为2 if x2 &amp;gt; bound: labels.</description>
    </item>
    
    <item>
      <title>Lenet</title>
      <link>https://wzchan.github.io/post/caffe/lenet/</link>
      <pubDate>Wed, 06 Dec 2017 15:16:55 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/lenet/</guid>
      <description>Lenet-5网络结构示意图: 第一层：输入层32x32（28x28）大小的图像。明显特征能够出现在最高层特征监测子感受野的中心。（笔画断续、角点）
第二层：C1，卷积层。原始信号特征增强，降低噪音，不同的卷积核能够提取到不同的图像特征。
 feature map个数：6个 32 * 32
conv kernel大小：5 * 5
神经元个数：(32 - 5 + 1) * (32 - 5 + 1) = 28 * 28
训练参数个数： (5 * 5 + 1) * 6 = 156
连接数： (5 * 5 + 1)* (28 * 28) * 6 = 122304
 第三层：S2，下采样层。降低网络训练参数和模型的过拟合程度。两种方法：均值、最大值。
 feature map个数：6个14 * 14，与C1中的2 * 2的区域相连。
神经元计算：sigmoid (2 * 2 的输入相加 * 一个训练参数 + 该feature map的bias)</description>
    </item>
    
    <item>
      <title>Caffe训练日志的可视化图表生成</title>
      <link>https://wzchan.github.io/post/caffe/caffe%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E8%A1%A8%E7%94%9F%E6%88%90/</link>
      <pubDate>Wed, 06 Dec 2017 15:11:27 +0800</pubDate>
      
      <guid>https://wzchan.github.io/post/caffe/caffe%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E8%A1%A8%E7%94%9F%E6%88%90/</guid>
      <description> 在训练模型时，增加 -log_dir 路径参数来保证在相应路径下保存所需绘图的日志文件。并且将所需要进行分析的日志文件的后缀改为.log   将path_to_caffe\tools\extra下的三个文件拷贝到当前工作目录下，需要拷贝的文件如下。  需要注意的是，可以将最后一个的文件名改为plot_training_log.py方便查看使用。并且如果想要生成完整的可视化图表，这三个文件缺一不可。
 然后根据plot_training_log.py中的提示，在命令行中输入相应的参数，一般的命令格式为：  ...\plot_training_log.py param_types where_you_store_image.png where_your_log_is.log  其中可供选择的param_number如下：
Supported chart types: 0: Test accuracy vs. Iters 1: Test accuracy vs. Seconds 2: Test loss vs. Iters 3: Test loss vs. Seconds 4: Train learning rate vs. Iters 5: Train learning rate vs. Seconds 6: Train loss vs. Iters 7: Train loss vs. Seconds  PS:在制作lmdb时候调用convert_imageset来进行数据转换
D:\new_caffe\caffe\build\tools&amp;gt;convert_imageset.exe D:\python_caffe_test\Classification/  D:\python_caffe_test\Classification\train.txt D:\python_caffe_test\Classification\train_lmdb -resize_width 224 -resize_height 224 --shuffle  </description>
    </item>
    
  </channel>
</rss>